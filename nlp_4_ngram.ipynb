{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp-4-ngram.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMNxOS7DUQTGLLmGYGws0OG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/woneuy01/Hands-on-NLP-with-NLTK-and-Scikit-learn/blob/master/nlp_4_ngram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqeZxdqszZFW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "71e1d2c9-bb5e-404d-abbc-df4e8ed6aaa4"
      },
      "source": [
        "import collections\n",
        "import nltk\n",
        "import os\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from sklearn import(\n",
        "    datasets, model_selection, feature_extraction, linear_model, naive_bayes,\n",
        "    ensemble\n",
        ")\n",
        "\n",
        "def extract_features(corpus):\n",
        "  '''Extract TF-IDF features from corpus'''\n",
        "\n",
        "  sa_stop_words=nltk.corpus.stopwords.words(\"english\")\n",
        "\n",
        "  # words that might invert a sentence's meaning\n",
        "  # when these words deleted as stop wards the meaning can be changed\n",
        "  # So exclude from stop-words ie. no changes meaning the opposite\n",
        "  white_list = [\n",
        "        'what', 'but', 'if', 'because', 'as', 'until', 'against',\n",
        "        'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again',\n",
        "        'further', 'then', 'once', 'here', 'there', 'why', 'how', 'all', 'any',\n",
        "        'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own',\n",
        "        'same', 'so', 'than', 'too', 'can', 'will', 'just', 'don', 'should']\n",
        "\n",
        "  # take these out of the standard NLTK stop words list\n",
        "  sa_stop_words = [sw for sw in sa_stop_words if sw not in white_list]  \n",
        "\n",
        "  # vectroze means we turn non-numerical data into an array of numbers\n",
        "  count_vectorizer = feature_extraction.text.CountVectorizer(\n",
        "      lowercase=True,  # for demonstration, True by default\n",
        "      tokenizer=nltk.word_tokenize,  # use the NLTK tokenizer\n",
        "      min_df=2,  # minimum document frequency, i.e. the word must appear more than once.\n",
        "      ngram_range=(1, 2), # uni-gram and bi-gram\n",
        "      stop_words=sa_stop_words # after excluding white_list\n",
        "    )\n",
        "  processed_corpus = count_vectorizer.fit_transform(corpus)\n",
        "  processed_corpus = feature_extraction.text.TfidfTransformer().fit_transform(\n",
        "      processed_corpus)\n",
        "  \n",
        "  return processed_corpus\n",
        "\n",
        "data_directory = 'movie_reviews'\n",
        "movie_sentiment_data=datasets.load_files(data_directory, shuffle =True)\n",
        "print('{} files loaded.'.format(len(movie_sentiment_data.data)))\n",
        "print('They contain the following classes:{}.'.format(\n",
        "    movie_sentiment_data.target_names))\n",
        "\n",
        "movie_tfidf = extract_features(movie_sentiment_data.data)\n",
        "\n",
        "X_train, X_test, y_train,y_test = model_selection.train_test_split(\n",
        "    movie_tfidf, movie_sentiment_data.target, test_size =0.3, random_state =42)\n",
        "\n",
        "#similar to nltk.NaiveBayseClassifier.train()\n",
        "clf1 = linear_model.LogisticRegression()\n",
        "clf1.fit(X_train,y_train)\n",
        "print('Logistic Regression performance:{}'. format(clf1.score(X_test,y_test)))\n",
        "\n",
        "clf2 = linear_model.SGDClassifier()\n",
        "clf2.fit(X_train, y_train)\n",
        "print('SGDClassifier performance: {}'. format(clf2.score(X_test, y_test)))\n",
        "\n",
        "clf3 = naive_bayes.MultinomialNB()\n",
        "clf3.fit(X_train,y_train)\n",
        "print('MulinomialNB performance: {}'.format(clf3.score(X_test, y_test)))\n",
        "\n",
        "clf4 = naive_bayes.BernoulliNB()\n",
        "clf4.fit(X_train, y_train)\n",
        "print('BernoulliNB performance: {}'.format (clf4.score(X_test, y_test)))\n",
        "\n",
        "voting_model = ensemble.VotingClassifier(\n",
        "    estimators = [('lr', clf1),('sgd',clf2),('mnb',clf3),('bnb', clf4)],\n",
        "    voting='hard' # give one vote model soft means confidence take in to account\n",
        "    )\n",
        "voting_model.fit(X_train,y_train)\n",
        "print('Voting classifier performance: {}'.format(\n",
        "    voting_model.score(X_test, y_test)))\n",
        "\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "40 files loaded.\n",
            "They contain the following classes:['.ipynb_checkpoints', 'neg', 'pos'].\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'might', 'must', \"n't\", 'need', 'sha', 'should', 'wo', 'would'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Logistic Regression performance:0.5\n",
            "SGDClassifier performance: 0.6666666666666666\n",
            "MulinomialNB performance: 0.5\n",
            "BernoulliNB performance: 0.5\n",
            "Voting classifier performance: 0.5\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}